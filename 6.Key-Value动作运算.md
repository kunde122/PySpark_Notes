[TOC]

```python
# 1.Key-Value 获取元素: first, take,
kvRDD1 = sc.parallelize([(3, 4), (3, 6), (5, 6), (1, 2)])
kvRDD1.first()  # 获取第一个元素
kvRDD2.take(2)  # 获取前两个元素

# 2.collectAsMap 建立Key-Value字典: 返回字典
kvRDD1.collectAsMap()

# 3.Key-Value lookup运算: 输入key值来查找value,返回所有value组成的列表
kvRDD1.lookup(3)
kvRDD1.lookup(5)

"""
Shared varable共享变数. 共享变数可以节省记忆体与执行时间, 提升平行处理时的执行效率
共享变数包括:
    Broadcast广播变数
    accumulator累加器
"""
# 4.Broadcast广播变数
# 4.1 不使用Broadcast的范例
kvFruit = sc.parallelize([(1, 'apple'), (2, 'orange'), (3, 'banana'), (4, 'grape')])
fruitMap = kvFruit.collectAsMap()
fruitIds = sc.parallelize([2, 4, 1, 3])
fruitNames = fruitIds.map(lambda x: fruitMap[x]).collect()

# 4.2 使用Broadcast的范例
kvFruit = sc.parallelize([(1, 'apple'), (2, 'orange'), (3, 'banana'), (4, 'grape')])
bcFruitMap = sc.broadcast(fruitMap)  # 使用sc.broadcast传入fruitMap参数,建立bcFruitMap广播变数
fruitIds = sc.parallelize([2, 4, 1, 3])
fruitNames = fruitIds.map(lambda x: bcFruitMap.value[x]).collect()  # 使用bcFruitMap.value[x]广播变数,将fruitIds转化为fruitNames
"""
在平行处理中, bcFruitMap广播变数会传送到Worker Node机器, 并存储在记忆体中, 后续在此Worker Node都可以使用此bcFruitMap广播变数进行转换, 这样就可以节省很多记忆体与传送时间
"""

# 5.accumulator累加器
"""
加总是MapReduce常用的运算, 为增加平行化运算的执行效率, Spark特别提供accumulator累加器共享变数. 使用规则如下:
    * accumulator累加器可以使用SparkContext.accumulator(初始值)来建立
    * 使用.add()进行累加
    * 在task中, 例如foreach循环中, 不能读取累加器的值
    * 只有循环外才可以使用.value来读取累加器的值
"""

intRDD = sc.parallelize([3, 1, 2, 5, 5])
total = sc.accumulator(0.0)  # 建立total累加器,起始值使用0.0, 所以是double的类型
num = sc.accumulator(0)  # 建立num累加器, 起始值使用0, 所以是Int的类型
intRDD.foreach(lambda I: [total.add(I), num.add(1)])
avg = total.value/num.value

# 6.RDD Persistence持久化
"""
Spark RDD持久化机制, 可以让你将需要重复运算的RDD储存在记忆体中, 可大幅提高运算效率. 适用方法如下:
    * RDD.persist(参数): 在参数中你可以指定储存等级, 预设为MEMORY_ONLY, 也就是存在记忆体中(内存中)
    * RDD.unpersist(): 取消持久化

持久化储存等级参数说明如下:
    * MEMORY_ONLY: 默认选项,储存RDD的方式是以Java物件反序列化在JVM内存中.如果RDD而无法完全储存在内存, 多余RDD partions不会cache在内存中, 二十需要时再重新计算
    * MEMORY_AND_DISK: 先存在内存里, 若不够, 多余的存入硬盘, 需要时再从硬盘里读取
    * MEMORY_ONLY_SER: 与MEMORY_ONLY类似,但是存储RDD以Java物件序列化, 因为需要再进行反序列化才能使用, 所以会消耗更多CPU, 但是会节省存储空间. 多余RDD partitions不会存到内存, 需要时重新计算
    * MEMORY_AND_DISK_SER:与MEMEORY_ONLY_SIR类似, 多余的RDD partitions存储在磁盘, 需要时再读取
    * DISK_ONLY: 只存储在硬盘
    * MEMORY_ONLY_2, MEMORY_DISK_2, etc:与上列对应的选项一样, 但是每个RDD partitions都复制到2个节点
"""

# 6.1 使用RDD.persist()持久化
intRddMemory = sc.paralllelize([3, 1, 2, 5, 5])
intRddMemory.persist()
intRddMemory.is_cached  # 查看是否已经cached缓存
# 6.2 使用RDD.unpersist()取消持久化
intRddMemory.unpersist()
intRddMemory.is_cached()
```

> (3, 4)

> [(3, 4), (3, 6)]

> {1: 2, 3: 6, 5: 6}

> [4, 6]

> [6]

> True

> False
